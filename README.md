# otto8_local_model_tool

## Getting Started

1. Start a local model server, with one of the following options:
    - [tools.cpp](https://github.com/rubra-ai/tools.cpp)
    - lmstudio
    - [ollama](https://github.com/ollama/ollama)
    - [llama.cpp](https://github.com/ggerganov/llama.cpp)

make sure the server is accessible at `http://127.0.0.1:1234/v1/`
The easiest way to get started is lmstudio.

2. Go to Otto8 UI and register this tool, using the URL of this repo.

3. Add the tool to the agent and chat with it!